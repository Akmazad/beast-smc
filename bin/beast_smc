#!/usr/bin/env python3
# Author: Aaron Darling
# Author: Mathieu Fourment
# TODO: PEPify with docstrings
#
import sys
import argparse
import os
import math
import xml.etree.ElementTree as ET
from shutil import copyfile, rmtree
import numpy as np
from functools import partial
import subprocess
from subprocess import check_call


def resample_multinomial(weights):
    w = np.exp(weights)
    w /= sum(w)
    res = np.random.multinomial(len(weights), w)
    pIndexes = []
    for idx, count in enumerate(res):
        if count > 0:
            pIndexes.extend([idx]*count)
    assert len(pIndexes) == len(weights)
    return pIndexes


def resample_systematic(weights, stratified=False):
    # Procedure for stratified sampling
    # See Appendix of Kitagawa 1996, http://www.jstor.org/stable/1390750,
    # or p.290 of the Doucet et al book, an image of which is at:
    # http://cl.ly/image/200T0y473k1d/stratified_resampling.jpg

    w = np.exp(weights)
    w /= sum(w)

    cum = 0
    r = np.random.random_sample() * 1.0/len(weights)

    uCount = np.zeros(len(weights), dtype=np.int)
    j = 0
    for i, weight in enumerate(w):
        cum += weight
        while cum > ((float(j) / len(w)) + r):
            uCount[i] += 1
            j += 1

            # The only difference between stratified and systematic resampling
            # is whether a new random variable is drawn for each partition of
            # the (0, 1] interval.
            if stratified:
                r = np.random.random_sample() * 1.0/len(weights)

    pIndexes = []
    for idx, count in enumerate(uCount):
        if count > 0:
            pIndexes.extend([idx]*count)
    assert len(pIndexes) == len(weights)

    return pIndexes


def ESS(weights):
    sum = 0
    sumsq = 0
    for w in weights:
        sum += math.exp(w)
    for w in weights:
        sumsq += math.exp(2.0 * w)
    return math.exp(-math.log(sumsq) + 2 * math.log(sum))


def parse_taxon_list(xml_path):
    xml_tree = ET.parse(xml_path)
    taxa = xml_tree.find('taxa')
    taxa_set = set()
    for taxon in taxa.findall('taxon'):
        taxa_set.add(taxon.attrib['id'])
    return taxa_set


def read_ll(checkpoint_file):
    wf = open(checkpoint_file, 'r')
    for line in wf:
        if line.startswith('lnL'):
            ll = line.split('\t')
            return float(ll[1])
    return 0 #TODO: throw an error here


# Runs a single instance of BEAST on every particle
def beast_smc():
    os.makedirs(os.path.join(args.output, "iteration.0"))
    prev_ll = np.zeros(p_count)
    ckpnts = range(p_count)
    weights = [0]*p_count
    added_taxa = set()

    for i in range(p_count):
        ckpnt_file = os.path.join(args.output, "iteration.0", 'particle{}.part.out'.format(i))
        copyfile(os.path.join(args.checkpoint_dir, cp_files[i]), ckpnt_file)
        prev_ll[i] = read_ll(ckpnt_file)

    iter = 0
    for taxon in taxa_to_add:
        iter += 1
        iterdir = os.path.join(args.output, "iteration." + str(iter))
        os.mkdir(iterdir)
        new_ll = np.zeros(p_count)

        ptrees_file = os.path.join(iterdir, 'particle.trees')
        plog_file = os.path.join(iterdir, 'particle.log')
        pxml_file = os.path.join(iterdir, 'beast.xml')
        pout_file = os.path.join(iterdir, 'beast.add.out')
        perr_file = os.path.join(iterdir, 'beast.add.err')

        # remove any taxa and associated sequences that we are not yet ready to add
        added_taxa.add(taxon)
        remove_taxa = taxa_to_add.difference(added_taxa)
        pxml_tree = ET.parse(args.new_xml)
        taxa = pxml_tree.find('taxa')
        for t in taxa.findall('taxon'):
            if t.attrib['id'] in remove_taxa:
                taxa.remove(t)
        alignment = pxml_tree.find('alignment')
        for s in alignment.findall('sequence'):
            if s[0].attrib['idref'] in remove_taxa:  # gets the taxon for the sequence
                alignment.remove(s)
        # set the log file names for this particle
        mcmc = pxml_tree.find('mcmc')
        mcmc.attrib['chainLength'] = str(args.mcmc_iters)
        for l in mcmc.findall('log'):
            l.attrib['logEvery'] = str(args.mcmc_iters)
            if l.attrib['id'] == 'fileLog':
                l.attrib['fileName'] = plog_file
        lt = mcmc.find('logTree')
        lt.attrib['fileName'] = ptrees_file
        lt.attrib['logEvery'] = str(args.mcmc_iters)
        # TODO: add the targeted operator to the new XML
        pxml_tree.write(pxml_file)

        previous_iter = os.path.join(args.output, 'iteration.{}'.format(iter - 1))
        for p_id in range(p_count):
            prev_ckpnt_file = os.path.join(previous_iter, "particle{}.part.out".format(ckpnts[p_id]))
            new_ckpnt_file = os.path.join(iterdir, 'particle{}.part'.format(p_id))
            java_cmd = 'java -cp ' + beast_lib + ' dr.app.realtime.CheckPointUpdaterApp ' \
                                                 ' -BEAST_XML ' + pxml_file + \
                       ' -load_state ' + prev_ckpnt_file + \
                       ' -update_choice F84Distance ' + \
                       ' -output_file ' + new_ckpnt_file + \
                       ' > ' + pout_file + \
                       ' 2> ' + perr_file
            print(java_cmd)
            os.system(java_cmd)

            if os.path.lexists(plog_file):
                os.remove(plog_file)
            if os.path.lexists(ptrees_file):
                os.remove(ptrees_file)

            # read the new log likelihood
            new_ll[p_id] = read_ll(new_ckpnt_file)
            weights[p_id] += new_ll[p_id] - prev_ll[p_id]

        # compute the ESS
        ess = ESS(weights)
        print("ESS: " + str(ess))

        # optionally do resampling
        print("weights are:")
        print(weights)

        if ess < threshold:
            print("Resampling")
            ckpnts = resample[args.sampling](weights)
            print(ckpnts)
            weights = [1.0 / p_count] * p_count
            prev_ll = new_ll[ckpnts]
        else:
            prev_ll = new_ll
            ckpnts = range(p_count)

        if args.mcmc_iters <= 0:
            continue

        # run MCMC on all particles
        cmd = (beast_exe, '-particles', iterdir, '-overwrite ', pxml_file)
        print(' '.join(cmd))
        with open(os.devnull, 'w') as FNULL:
            check_call(cmd, stdout=FNULL, stderr=FNULL)

        for p_id in range(p_count):
            ckpnt_file = os.path.join(iterdir, 'particle{}.part.out'.format(p_id))
            prev_ll[p_id] = read_ll(ckpnt_file)

        ckpnts = range(p_count)


parser = argparse.ArgumentParser(description='Add sequences to a BEAST run using SMC.')
parser.add_argument('--checkpoint_dir', metavar='cpdir', type=str,
                    help='the location of the BEAST checkpoint directory',
                    required=True)
parser.add_argument('--original_xml', type=str, help='The original BEAST XML file',
                    required=True)
parser.add_argument('--new_xml', type=str, help='The BEAST XML file with new sequences',
                    required=True)
parser.add_argument('--particles', type=int,
                    help='The number of particles to use', default=1000)
parser.add_argument('--mcmc_iters', type=int,
                    help='The number of MCMC iterations after each' \
                    ' sequence addition', default=500)
parser.add_argument('--beast', type=str, help='The full path to the beast release')
parser.add_argument('--output', type=str, help='A destination directory for output',
                    default='output')
parser.add_argument('--threshold', type=float, help='Resampling threshold. If threshold is positive and less than 1'
                                                    'then resampling is triggered when ESS < threshold*particles. If'
                                                    ' threshold > 1 then resampling is triggered when threshold < ESS.',
                    default=0.5)
parser.add_argument('--sampling', default='multinomial', choices=['multinomial', 'stratified', 'systematic'],
                    help='Sampling method')
parser.add_argument('--overwrite', help='Overwrite output folder', action='store_true')
args = parser.parse_args()

if os.path.lexists(args.output) and args.overwrite:
    rmtree(args.output)

resample_stratified = partial(resample_systematic, stratified=True)
resample = {
    'systematic': resample_systematic,
    'stratified': resample_stratified,
    'multinomial': resample_multinomial,
}

beast_path = os.path.abspath(args.beast)
beast_lib = '"{}"'.format(os.path.join(beast_path, 'lib', 'beast.jar'))
beast_exe = os.path.join(beast_path, 'bin', 'beast')
orig_xml_path = os.path.abspath(args.original_xml)
new_xml_path = os.path.abspath(args.new_xml)

# parse the original BEAST XML to get a taxon list
orig_taxa_set = parse_taxon_list(orig_xml_path)

# parse the new BEAST XML to find the new taxa
new_taxa_set = parse_taxon_list(new_xml_path)

taxa_to_add = new_taxa_set.difference(orig_taxa_set)

cp_files = os.listdir(args.checkpoint_dir)
cp_files = [f for f in cp_files if f.startswith('beast_state')]
if len(cp_files) < args.particles:
    sys.stderr.write('ERROR: number of particles requested exceeds number '
    'of MCMC checkpoints. Set --particles to a smaller value or run more MCMC '
    'on your original data set.\n\n')
    sys.exit(-1)
p_count = args.particles

threshold = args.threshold
if args.threshold < 1:
    threshold = args.threshold*p_count

one_beast = True
if one_beast:
    beast_smc()
    exit(0)

# set up particles for iteration 0 from MCMC checkpoints
os.makedirs(os.path.join(args.output, "iteration.0"))
prev_ll = np.zeros(p_count)
ckpnts = range(p_count)
weights = [0]*p_count

for i in range(p_count):
    particle_dir = os.path.join(args.output, "iteration.0", "particle."+str(i))
    os.mkdir(particle_dir)
    ckpnt_file = os.path.join(particle_dir, 'particle.ckpnt')
    # TODO: when there's an excess of checkpoint files, select in a less arbitrary manner
    copyfile(os.path.join(args.checkpoint_dir, cp_files[i]), ckpnt_file)
    prev_ll[i] = read_ll(ckpnt_file)

# now start hybrid SMC/MCMC iterations to add new taxa
iter = 0
added_taxa = set()
for taxon in taxa_to_add:
    iter+=1
    iterdir = os.path.join(args.output, "iteration."+str(iter))
    os.mkdir(iterdir)
    new_ll = np.zeros(p_count)
    for p_id in range(p_count):
        particle_dir = os.path.join(iterdir, "particle."+str(p_id))
        os.mkdir(particle_dir)
        ckpnt_file = os.path.join(particle_dir, 'particle.ckpnt')
        ptrees_file = os.path.join(particle_dir, 'particle.trees')
        plog_file = os.path.join(particle_dir, 'particle.log')
        pxml_file = os.path.join(particle_dir, 'beast.xml')
        pout_file = os.path.join(particle_dir, 'beast.add.out')
        perr_file = os.path.join(particle_dir, 'beast.add.err')

        # remove any taxa and associated sequences that we are not yet ready to add
        added_taxa.add(taxon)
        remove_taxa = taxa_to_add.difference(added_taxa)
        pxml_tree = ET.parse(args.new_xml)
        taxa = pxml_tree.find('taxa')
        for t in taxa.findall('taxon'):
            if t.attrib['id'] in remove_taxa:
                taxa.remove(t)
        alignment = pxml_tree.find('alignment')
        for s in alignment.findall('sequence'):
            if s[0].attrib['idref'] in remove_taxa: # gets the taxon for the sequence
                alignment.remove(s)
        # set the log file names for this particle
        mcmc = pxml_tree.find('mcmc')
        mcmc.attrib['chainLength']=str(args.mcmc_iters)
        for l in mcmc.findall('log'):
            l.attrib['logEvery']=str(args.mcmc_iters)
            if l.attrib['id']=='fileLog':
                l.attrib['fileName']=plog_file
        lt = mcmc.find('logTree')
        lt.attrib['fileName']=ptrees_file
        lt.attrib['logEvery']=str(args.mcmc_iters)
        # TODO: add the targeted operator to the new XML
        pxml_tree.write(pxml_file)

        prev_ckpnt_file = os.path.join(args.output, "iteration."+str(iter-1), "particle."+str(ckpnts[p_id]), "particle.ckpnt")
        new_ckpnt_file = os.path.join(iterdir, "particle."+str(p_id), "particle.ckpnt")
        java_cmd = 'java -cp ' + beast_lib + ' dr.app.realtime.CheckPointUpdaterApp ' \
            ' -BEAST_XML ' + pxml_file + \
            ' -load_state ' + prev_ckpnt_file + \
            ' -update_choice F84Distance ' + \
            ' -output_file ' + new_ckpnt_file + \
            ' > ' + pout_file + \
            ' 2> ' + perr_file
        print(java_cmd)
        os.system(java_cmd)

        # read the new log likelihood
        new_ll[p_id] = read_ll(new_ckpnt_file)
        weights[p_id] += new_ll[p_id] - prev_ll[p_id]

    # compute the ESS
    ess = ESS(weights)
    print("ESS: "+str(ess))

    # optionally do resampling
    print("weights are:")
    print(weights)

    if ess < threshold:
        print("Resampling")
        ckpnts = resample[args.sampling](weights)
        print(ckpnts)
        weights = [1.0/p_count]*p_count
        prev_ll = new_ll[ckpnts]
    else:
        prev_ll = new_ll
        ckpnts = range(p_count)

    if args.mcmc_iters <= 0:
        continue

    # now run MCMC on each particle
    for p_id in range(p_count):
        particle_dir = os.path.join(iterdir, 'particle.'+str(p_id))
        ckpnt_file = os.path.join(particle_dir, 'particle.ckpnt')
        mcmc_ckpnt_file = os.path.join(particle_dir, 'particle.mcmc.ckpnt')
        pxml_file = os.path.join(particle_dir, 'beast.xml')
        pout_file = os.path.join(particle_dir, 'beast.mcmc.out')
        perr_file = os.path.join(particle_dir, 'beast.mcmc.err')

        java_cmd = 'java -jar ' + beast_lib + \
            ' -load_state ' + os.path.join(iterdir, 'particle.{}'.format(ckpnts[p_id]), 'particle.ckpnt') + \
            ' -save_at ' + str(args.mcmc_iters) + \
            ' -save_state ' + mcmc_ckpnt_file + \
            ' -force_resume ' + \
            ' -overwrite ' + \
            pxml_file + \
            ' > ' + pout_file + \
            ' 2> ' + perr_file
        print(java_cmd)
        os.system(java_cmd)
        os.system('mv '+mcmc_ckpnt_file+' '+ckpnt_file)

        # read the new log likelihood
        prev_ll[p_id] = read_ll(ckpnt_file)

    ckpnts = range(p_count)
